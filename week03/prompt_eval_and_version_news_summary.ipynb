{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d5b333b",
   "metadata": {},
   "source": [
    "\n",
    "# Week03 — Prompt Evaluation & Version Management (Langfuse + Notion + GitHub)\n",
    "\n",
    "이 노트북은 **뉴스 기사 10개**를 입력으로 받아,  \n",
    "- **V0.0.1 (간단 요약 Prompt)**, **V0.0.2 (구조화된 뉴스 요약 Prompt)** 두 번의 Prompt Engineering을 수행하고,  \n",
    "- **Langfuse Tracing**을 남기며,  \n",
    "- **Langfuse Datasets**에 평가용 샘플 10개를 업로드하고,  \n",
    "- 이후 **Dataset Run/Evaluation**을 할 수 있도록 기본 코드를 제공합니다.\n",
    "\n",
    "> ⚙️ 이 노트북은 `.env`에 저장된 다음 변수들을 사용합니다.\n",
    "> - `LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY`, `LANGFUSE_HOST` (예: `https://cloud.langfuse.com` 또는 리전 URL)\n",
    "> - `OPENAI_API_KEY` (또는 호환 LLM API 키)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1ccfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langfuse python-dotenv openai requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be11d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env\n",
      "Langfuse host: https://cloud.langfuse.com\n",
      "Langfuse public key set?  True\n",
      "Langfuse secret key set?  True\n",
      "OpenAI key set?  True\n"
     ]
    }
   ],
   "source": [
    "# --- 0) 설치 & 기본 설정 ---------------------------------------------------------\n",
    "# 인터넷 환경에 따라 설치가 제한될 수 있습니다. 로컬 환경에서 실행하세요.\n",
    "# %pip install -q langfuse python-dotenv openai requests\n",
    "\n",
    "import os, json, time, uuid, sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "\n",
    "# .env 로드\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    print(\"Loaded .env\")\n",
    "except Exception as e:\n",
    "    print(\"python-dotenv not available; make sure environment variables are set.\")\n",
    "\n",
    "LANGFUSE_PUBLIC_KEY = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
    "LANGFUSE_SECRET_KEY = os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
    "LANGFUSE_HOST = os.getenv(\"LANGFUSE_HOST\", \"https://cloud.langfuse.com\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"Langfuse host:\", LANGFUSE_HOST)\n",
    "print(\"Langfuse public key set? \", bool(LANGFUSE_PUBLIC_KEY))\n",
    "print(\"Langfuse secret key set? \", bool(LANGFUSE_SECRET_KEY))\n",
    "print(\"OpenAI key set? \", bool(OPENAI_API_KEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8ac2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sample news: news_01.txt\n",
      "Length: 1408\n",
      "\n",
      "--- Preview (first 800 chars) ---\n",
      "\n",
      "LG가 런던증권거래소그룹(LSEG)와 손잡고 독자 인공지능(AI) 모델 ‘엑사원’(EXAONE)을 기반으로 한 ‘금융 AI 에이전트’의 상용화에 나섰다. 이번 협업은 양국간 첫 ‘금융 AI’ 협력 사례로, 한국의 AI 기술력이 글로벌 시장으로 확산하는 계기가 될 것으로 전망된다.\n",
      "\n",
      "LG는 자사 AI연구원과 LSEG가 지난 19일(현지시각) 영국 런던증권거래소에서 금융 AI 에이전트 ‘엑사원 비즈니스 인텔리전스’ 상용화 서비스 시작을 알리는 행사를 진행했다고 21일 밝혔다.\n",
      "\n",
      "이날 행사에는 토드 하트만 데이터·피드 그룹 총괄, 이보 데커스 유럽·중동·아프리카 영업 그룹 총괄, 사이먼 유든 퀀트·데이터 총괄, 앤드류 파이프 아시아태평양 지역 영업 총괄을 비롯한 LSEG 경영진과 이홍락 공동 연구원장, 임우형 공동 연구원장, 이화영 AI사업개발부문장 등 LG AI연구원 경영진이 참석했다.\n",
      "\n",
      "토드 하트만 총괄은 “LG와의 파트너십은 새로운 시작을 의미한다”며 “AI는 전 세계 투자자들에게 예측부터 의사결정 지원에 이르기까지 더 나은 기회를 제공하는 핵심적인 역할을 할 것”이라고 말했다.\n",
      "\n",
      "LSEG는 글로벌 금융 인프라·데이터 분야를 선도하는 영국 대표 금융 기업으로, 런던증권거래소를 운영하고 있다.\n",
      "\n",
      "LSEG는 금융 시장의 방대한 데이터와 이를 분석한 자료를 전 세계 투자자들에게 제공하는 것을 핵심 사업으로 삼고 있다. 이 핵심 사업에 LG AI연구원의 금융 AI 에이전트 ‘엑사원-BI’를 도입하는 것이다.\n",
      "\n",
      "‘엑사원-BI’는 인간 개입 없이 AI가 데이터 분석부터 미래 예측, 보고서 작성까지 전 과정을 수행하는 ‘\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1) 뉴스 기사 로드 ------------------------------------------------------\n",
    "news_dir = Path(\"datasets/news\")\n",
    "news_files = sorted(list(news_dir.glob(\"news_*.txt\")))\n",
    "\n",
    "# 첫 번째 뉴스 기사를 데모용으로 로드\n",
    "sample_news_text = \"\"\n",
    "if news_files:\n",
    "    try:\n",
    "        with open(news_files[0], \"r\", encoding=\"utf-8\") as f:\n",
    "            sample_news_text = f.read()\n",
    "            print(\"Loaded sample news:\", news_files[0].name)\n",
    "            print(\"Length:\", len(sample_news_text))\n",
    "            print(\"\\n--- Preview (first 800 chars) ---\\n\")\n",
    "            print(sample_news_text[:800])\n",
    "    except Exception as e:\n",
    "        print(\"Error loading sample news:\", e)\n",
    "        sample_news_text = \"LG가 런던증권거래소그룹(LSEG)와 손잡고 독자 인공지능(AI) 모델 '엑사원'(EXAONE)을 기반으로 한 '금융 AI 에이전트'의 상용화에 나섰다... (샘플 뉴스)\"\n",
    "else:\n",
    "    print(\"No news files found in datasets/news directory\")\n",
    "    sample_news_text = \"LG가 런던증권거래소그룹(LSEG)와 손잡고 독자 인공지능(AI) 모델 '엑사원'(EXAONE)을 기반으로 한 '금융 AI 에이전트'의 상용화에 나섰다... (샘플 뉴스)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108cbc7c",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Prompts — V0.0.1 (간단 요약) vs V0.0.2 (구조화 회의록)\n",
    "\n",
    "- **V0.0.1**: 간단 요약\n",
    "- **V0.0.2**: 자세한 요약\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "975987be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "V001_SIMPLE_SUMMARY = '''You are a news summarizer.\n",
    "Summarize the following news article in **one short paragraph (max 120 words)**.\n",
    "Focus only on the most important facts: who, what, when, where, and why.\n",
    "Do not add opinions or speculation.\n",
    "\n",
    "Write in 'Korean'\n",
    "'''\n",
    "\n",
    "V002_STRUCTURED_MINUTES = '''You are an expert news analyst.\n",
    "Summarize the following news article into a **structured Markdown report** with the following sections:\n",
    "\n",
    "# Headline\n",
    "- A concise title (≤15 words) that captures the main story\n",
    "\n",
    "# Summary\n",
    "- 1–2 paragraphs describing the main events in neutral tone\n",
    "\n",
    "# Key Points\n",
    "- 3–5 bullet points with the most critical facts (who, what, when, where, why, how)\n",
    "\n",
    "# Implications\n",
    "- 2–3 sentences on potential impacts (political, economic, or social)\n",
    "\n",
    "# Quotes\n",
    "- Up to 2 direct quotes if available in the article\n",
    "\n",
    "Rules:\n",
    "- Remain objective, no speculation beyond the article content.\n",
    "- Do not exceed 300 words in total.\n",
    "- Preserve named entities (people, organizations, places) accurately.\n",
    "- Write in 'Korean'\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73550eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 3) LLM 호출 추상화 -----------------------------------------------------------\n",
    "def call_openai_chat(system_prompt: str, user_text: str, model: str = \"gpt-4o-mini\", temperature: float = 0.2) -> str:\n",
    "    \"\"\"LLM 호출. OPENAI_API_KEY가 없으면 모의 출력(mock)으로 대체.\"\"\"\n",
    "    if os.getenv(\"OPENAI_API_KEY\"):\n",
    "        try:\n",
    "            # Try official openai package first\n",
    "            try:\n",
    "                from openai import OpenAI\n",
    "                client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_text},\n",
    "                    ],\n",
    "                    temperature=temperature,\n",
    "                )\n",
    "                return resp.choices[0].message.content\n",
    "            except Exception:\n",
    "                # Fallback to raw HTTP if new package not available\n",
    "                import requests\n",
    "                headers = {\n",
    "                    \"Authorization\": f\"Bearer {os.getenv('OPENAI_API_KEY')}\",\n",
    "                    \"Content-Type\": \"application/json\",\n",
    "                }\n",
    "                payload = {\n",
    "                    \"model\": model,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_text},\n",
    "                    ],\n",
    "                    \"temperature\": temperature,\n",
    "                }\n",
    "                r = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload, timeout=60)\n",
    "                r.raise_for_status()\n",
    "                data = r.json()\n",
    "                return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except Exception as e:\n",
    "            print(\"OpenAI call failed, falling back to mock. Error:\", e)\n",
    "    # Mock output for offline demo\n",
    "    return f\"\"\"[MOCK OUTPUT]\\nSystem: {system_prompt.splitlines()[0]}\\nUserInputPreview: {user_text[:120]}...\\n- Bullet 1\\n- Bullet 2\\n- Bullet 3\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec0eb1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse SDK authenticated.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 4) Langfuse 초기화 & Tracing 유틸 -------------------------------------------\n",
    "USE_SDK = False\n",
    "langfuse = None\n",
    "\n",
    "try:\n",
    "    from langfuse import get_client, observe\n",
    "    from langfuse.openai import OpenAI as LFOpenAI  # optional\n",
    "    langfuse = get_client()\n",
    "    if langfuse and langfuse.auth_check():\n",
    "        USE_SDK = True\n",
    "        print(\"Langfuse SDK authenticated.\")\n",
    "    else:\n",
    "        print(\"Langfuse SDK not authenticated; will use HTTP or no-op.\")\n",
    "except Exception as e:\n",
    "    print(\"Langfuse SDK not available; continuing without it.\", e)\n",
    "\n",
    "def start_trace(name: str, metadata: Dict[str, Any] = None):\n",
    "    if USE_SDK:\n",
    "        # Start span as root trace context manager\n",
    "        return langfuse.start_as_current_span(name=name, metadata=metadata or {})\n",
    "    else:\n",
    "        # No-op context manager\n",
    "        from contextlib import contextmanager\n",
    "        @contextmanager\n",
    "        def _noop():\n",
    "            class Dummy:\n",
    "                def score_trace(self, *args, **kwargs): pass\n",
    "                def update_trace(self, *args, **kwargs): pass\n",
    "            yield Dummy()\n",
    "        return _noop()\n",
    "\n",
    "def log_trace_io(input_obj: Any, output_obj: Any):\n",
    "    if USE_SDK:\n",
    "        try:\n",
    "            # update current trace input/output to enable dataset evals linkage\n",
    "            langfuse.update_current_trace(input=input_obj, output=output_obj)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to update current trace:\", e)\n",
    "\n",
    "def flush_langfuse():\n",
    "    try:\n",
    "        if USE_SDK:\n",
    "            langfuse.flush()\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cc6902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== V0.0.1 (simple) ===\n",
      " LG는 런던증권거래소그룹(LSEG)과 협력하여 독자 인공지능 모델 '엑사원'(EXAONE)을 기반으로 한 '금융 AI 에이전트'의 상용화를 시작했다. 이 협업은 한국의 AI 기술을 글로벌 시장에 확산시키는 첫 사례로, 19일 런던증권거래소에서 상용화 서비스 시작을 알리는 행사가 열렸다. '엑사원-BI'는 AI가 데이터 분석, 예측, 보고서 작성 등을 수행하며, LSEG는 이를 통해 전 세계 투자자들에게 데이터 상품을 판매할 예정이다. LG AI연구원은 이 AI 에이전트가 새로운 AI 시대를 여는 시작점이 될 것으로 기대하고 있다. ...\n",
      "\n",
      "=== V0.0.2 (structured) ===\n",
      " # Headline\n",
      "LG, LSEG와 협력해 금융 AI 에이전트 '엑사원' 상용화\n",
      "\n",
      "# Summary\n",
      "LG가 런던증권거래소그룹(LSEG)과 협력하여 독자 인공지능(AI) 모델 '엑사원'(EXAONE)을 기반으로 한 '금융 AI 에이전트'의 상용화에 나섰다. 이 협업은 한국의 AI 기술이 글로벌 시장으로 확산하는 계기가 될 것으로 기대되며, 지난 19일 영국 런던증권거래소에서 상용화 서비스 시작을 알리는 행사가 개최됐다.\n",
      "\n",
      "행사에는 LSEG와 LG AI연구원 경영진이 참석했으며, LSEG의 토드 하트만 총괄은 LG와의 파트너십이 AI의 핵심 역할을 강조했다. '엑사원-BI'는 AI가 데이터 분석부터 예측, 보고서 작성까지 전 과정을 수행하는 금융 AI 에이전트로, LSEG는 이를 통해 전 세계 투자자들에게 데이터 상품을 판매할 예정이다.\n",
      "\n",
      "# Key Points\n",
      "- LG와 LSEG가 협력하여 '엑사원-BI' 금융 AI 에이전트를 상용화.\n",
      "- 상용화 발표는 19일 런던증권거래소에서 진행됨.\n",
      "- '엑사원-BI'는 AI가 데이터 분석과 예측을 수행하는 시스템.\n",
      "- LSEG는 이 AI 에이전트를 통해 데이터 상품 'AEFS'를 판매할 계획.\n",
      "- LG AI연구원은 이 협력이 AI를 활용한 수익 창출의 시작점이 될 것이라고 기대.\n",
      "\n",
      "# Implications\n",
      "이번 협력은 한국의 AI 기술이 글로벌 금융 시장에서의 경쟁력을 높이는 계기가 될 수 있으며, AI 기반의 데이터 분석 서비스가 투자자들에게 더 나은 의사결정 지원을 제공할 것으로 예상된다.\n",
      "\n",
      "# Quotes\n",
      "- \"LG와의 파트너십은 새로운 시작을 의미한다.\" - 토 ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 5) 두 가지 Prompt 실행 + Tracing --------------------------------------------\n",
    "subset = sample_news_text[:4000]  # 데모를 위해 앞부분만 사용\n",
    "\n",
    "results = {}\n",
    "\n",
    "with start_trace(name=\"news-summary:v0.0.1\", metadata={\"version\": \"v0.0.1\", \"label\": \"dev\", \"use_case\":\"news-summary\"}) as span:\n",
    "    out1 = call_openai_chat(V001_SIMPLE_SUMMARY, subset)\n",
    "    results[\"v0.0.1\"] = out1\n",
    "    log_trace_io({\"news_article\": subset, \"prompt_version\": \"v0.0.1\"}, {\"summary\": out1})\n",
    "\n",
    "with start_trace(name=\"news-summary:v0.0.2\", metadata={\"version\": \"v0.0.2\", \"label\": \"staging\", \"use_case\":\"news-summary\"}) as span:\n",
    "    out2 = call_openai_chat(V002_STRUCTURED_MINUTES, subset)\n",
    "    results[\"v0.0.2\"] = out2\n",
    "    log_trace_io({\"news_article\": subset, \"prompt_version\": \"v0.0.2\"}, {\"summary\": out2})\n",
    "\n",
    "flush_langfuse()\n",
    "\n",
    "print(\"\\n=== V0.0.1 (simple) ===\\n\", results[\"v0.0.1\"][:800], \"...\")\n",
    "print(\"\\n=== V0.0.2 (structured) ===\\n\", results[\"v0.0.2\"][:800], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffda36",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Langfuse Dataset 생성 & 아이템 업로드 (뉴스 10개)\n",
    "\n",
    "- 뉴스 기사 10개를 input으로, 기대 구조를 reference로 저장합니다.  \n",
    "- 이후 Langfuse에서 **Dataset Run**을 실행하여, 각 Prompt 버전의 결과를 비교/평가할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "144d0eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 news files\n",
      "Loaded news_01.txt: 1406 characters\n",
      "Loaded news_02.txt: 1231 characters\n",
      "Loaded news_03.txt: 1057 characters\n",
      "Loaded news_04.txt: 764 characters\n",
      "Loaded news_05.txt: 1342 characters\n",
      "Loaded news_06.txt: 1156 characters\n",
      "Loaded news_07.txt: 1476 characters\n",
      "Loaded news_08.txt: 1885 characters\n",
      "Loaded news_09.txt: 989 characters\n",
      "Loaded news_10.txt: 2064 characters\n",
      "\n",
      "Total news items for dataset: 10\n",
      "Created dataset 'week03_news_summary_demo' with 10 items via SDK.\n",
      "Local backup dataset written to /Users/hajuheon/Task/ai/ajou/25-2/llmops/week03/datasets/week03_news_summary_demo.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dataset 이름\n",
    "DATASET_NAME = \"week03_news_summary_demo\"\n",
    "\n",
    "# 뉴스 파일들 로드\n",
    "news_dir = Path(\"datasets/news\")\n",
    "news_files = sorted(list(news_dir.glob(\"news_*.txt\")))\n",
    "print(f\"Found {len(news_files)} news files\")\n",
    "\n",
    "# 뉴스 파일들을 읽어서 데이터셋 아이템으로 변환\n",
    "news_items = []\n",
    "for news_file in news_files:\n",
    "    try:\n",
    "        with open(news_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read().strip()\n",
    "            if content:  # 빈 파일이 아닌 경우만 추가\n",
    "                news_items.append({\n",
    "                    \"input\": {\"news_article\": content},\n",
    "                    \"expected_output\": {\n",
    "                        \"sections\": [\"Headline\", \"Summary\", \"Key Points\", \"Implications\", \"Quotes\"],\n",
    "                        \"word_count_limit\": 300\n",
    "                    }\n",
    "                })\n",
    "                print(f\"Loaded {news_file.name}: {len(content)} characters\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {news_file.name}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal news items for dataset: {len(news_items)}\")\n",
    "\n",
    "created = False\n",
    "if USE_SDK:\n",
    "    try:\n",
    "        langfuse.create_dataset(name=DATASET_NAME)\n",
    "        for item in news_items:\n",
    "            langfuse.create_dataset_item(\n",
    "                dataset_name=DATASET_NAME,\n",
    "                input=item[\"input\"],\n",
    "                expected_output=item[\"expected_output\"]\n",
    "            )\n",
    "        created = True\n",
    "        print(f\"Created dataset '{DATASET_NAME}' with {len(news_items)} items via SDK.\")\n",
    "    except Exception as e:\n",
    "        print(\"SDK dataset creation failed:\", e)\n",
    "\n",
    "# 로컬 JSONL도 함께 저장(백업/수동 업로드용)\n",
    "ds_dir = Path(\"datasets\"); ds_dir.mkdir(exist_ok=True)\n",
    "jsonl_path = ds_dir / f\"{DATASET_NAME}.jsonl\"\n",
    "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in news_items:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "print(\"Local backup dataset written to\", jsonl_path.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56eb65",
   "metadata": {},
   "source": [
    "\n",
    "## 7) (선택) Native Dataset Run 실행 예시\n",
    "\n",
    "아래 코드는 Langfuse **Datasets Cookbook**의 패턴을 따라, 각 Dataset Item을 순회하며 애플리케이션을 실행하고  \n",
    "`root_span.score_trace(...)` 등으로 평가 스코어를 기록합니다.  \n",
    "실행 전, SDK 인증이 되어 있어야 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d3d03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_evaluation_results():\n",
    "    \"\"\"\n",
    "    Langfuse에서 평가 결과를 분석하고 요약 통계를 출력합니다.\n",
    "    \"\"\"\n",
    "    if not USE_SDK:\n",
    "        print(\"Langfuse SDK unavailable; cannot analyze results.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # 데이터셋 정보 가져오기\n",
    "        dataset = langfuse.get_dataset(DATASET_NAME)\n",
    "        print(f\"\\n📊 Dataset Analysis: {DATASET_NAME}\")\n",
    "        print(f\"Total items: {len(dataset.items)}\")\n",
    "        \n",
    "        # 각 실행에 대한 통계 계산\n",
    "        runs = [\"news_summary_v0.0.1\", \"news_summary_v0.0.2\"]\n",
    "        \n",
    "        for run_name in runs:\n",
    "            print(f\"\\n🔍 Run: {run_name}\")\n",
    "            \n",
    "            # 해당 실행의 모든 스코어 수집\n",
    "            scores = {\n",
    "                'section_coverage': [],\n",
    "                'summary_quality': [],\n",
    "                'overall_score': []\n",
    "            }\n",
    "            \n",
    "            for item in dataset.items:\n",
    "                # 각 아이템의 실행 결과에서 스코어 추출\n",
    "                # 실제 구현에서는 Langfuse API를 통해 스코어 데이터를 가져와야 함\n",
    "                pass\n",
    "            \n",
    "            print(f\"  📈 Scores will be displayed after evaluation completion\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing results: {e}\")\n",
    "\n",
    "# 평가 결과 분석 (선택적 실행)\n",
    "# analyze_evaluation_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52455b07",
   "metadata": {},
   "source": [
    "## 📊 LLM-as-a-Judge 평가 시스템\n",
    "\n",
    "위의 코드는 뉴스 요약 품질을 평가하는 **LLM-as-a-Judge** 시스템을 구현합니다.\n",
    "\n",
    "### 평가 지표:\n",
    "\n",
    "1. **`section_coverage`** (구조적 완성도, 30% 가중치)\n",
    "   - 요약이 예상 섹션들(Headline, Summary, Key Points, Implications, Quotes)을 얼마나 잘 포함하는지 평가\n",
    "\n",
    "2. **`summary_quality`** (LLM 품질 평가, 70% 가중치)\n",
    "   - 핵심 정보 보존도 (30%)\n",
    "   - 요약 정확성 (25%) \n",
    "   - 구조적 완성도 (20%)\n",
    "   - 정보 압축도 (15%)\n",
    "   - 객관성 (10%)\n",
    "\n",
    "3. **`overall_score`** (종합 점수)\n",
    "   - 구조적 완성도 × 0.3 + 품질 평가 × 0.7\n",
    "\n",
    "### 사용법:\n",
    "1. 위의 셀을 실행하여 두 프롬프트 버전을 평가합니다\n",
    "2. Langfuse 대시보드에서 상세한 결과를 확인할 수 있습니다\n",
    "3. 각 뉴스 기사별로 세 가지 점수가 기록됩니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f02db63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting evaluation for both prompt versions...\n",
      "============================================================\n",
      "\n",
      "🔍 Evaluating V0.0.1 (Simple Summary)...\n",
      "Starting dataset run 'news_summary_v0.0.1' with 10 items...\n",
      "Processing item 1/10...\n",
      "  - Structure: 0.000, Quality: 0.850, Overall: 0.595\n",
      "Processing item 2/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 3/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 4/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 5/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 6/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 7/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 8/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 9/10...\n",
      "  - Structure: 0.000, Quality: 0.850, Overall: 0.595\n",
      "Processing item 10/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Finished dataset run 'news_summary_v0.0.1' on dataset 'week03_news_summary_demo'.\n",
      "\n",
      "============================================================\n",
      "\n",
      "🔍 Evaluating V0.0.2 (Structured Summary)...\n",
      "Starting dataset run 'news_summary_v0.0.2' with 10 items...\n",
      "Processing item 1/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 2/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 3/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 4/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 5/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 6/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 7/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 8/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 9/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 10/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Finished dataset run 'news_summary_v0.0.2' on dataset 'week03_news_summary_demo'.\n",
      "\n",
      "============================================================\n",
      "✅ Evaluation completed! Check Langfuse dashboard for detailed results.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def presence_of_sections_eval(output_text: str, expected_sections) -> float:\n",
    "    \"\"\"출력에 예상 섹션 헤더가 얼마나 포함되는지 0.0~1.0 반환.\"\"\"\n",
    "    if not output_text:\n",
    "        return 0.0\n",
    "    hits = 0\n",
    "    for sec in expected_sections:\n",
    "        if f\"# {sec}\" in output_text or sec in output_text:\n",
    "            hits += 1\n",
    "    return hits / max(1, len(expected_sections))\n",
    "\n",
    "def llm_judge_summary_quality(original_text: str, summary_text: str) -> float:\n",
    "    \"\"\"\n",
    "    LLM-as-a-judge 방식으로 뉴스 요약의 품질을 평가합니다.\n",
    "    0.0~1.0 스케일로 점수를 반환합니다.\n",
    "    \"\"\"\n",
    "    if not original_text or not summary_text:\n",
    "        return 0.0\n",
    "    \n",
    "    evaluation_prompt = f\"\"\"당신은 뉴스 요약 품질 평가 전문가입니다. \n",
    "다음 원문과 요약을 비교하여 요약의 품질을 평가해주세요.\n",
    "\n",
    "평가 기준:\n",
    "1. 핵심 정보 보존도 (30%): 원문의 중요한 사실, 인물, 시간, 장소, 숫자 등이 얼마나 잘 보존되었는가?\n",
    "2. 요약 정확성 (25%): 요약된 내용이 원문과 일치하는가? 잘못된 정보나 왜곡이 없는가?\n",
    "3. 구조적 완성도 (20%): 요약이 논리적이고 읽기 쉽게 구성되었는가?\n",
    "4. 정보 압축도 (15%): 원문의 핵심만을 효율적으로 압축했는가?\n",
    "5. 객관성 (10%): 요약이 중립적이고 객관적인가? 개인 의견이나 추측이 없는가?\n",
    "\n",
    "원문:\n",
    "{original_text[:2000]}\n",
    "\n",
    "요약:\n",
    "{summary_text}\n",
    "\n",
    "평가 점수를 0.0에서 1.0 사이의 실수로만 응답해주세요. \n",
    "추가 설명 없이 숫자만 출력하세요.\n",
    "예: 0.85\"\"\"\n",
    "\n",
    "    try:\n",
    "        score_text = call_openai_chat(\n",
    "            system_prompt=\"당신은 뉴스 요약 품질 평가 전문가입니다. 주어진 기준에 따라 객관적이고 정확한 평가를 해주세요.\",\n",
    "            user_text=evaluation_prompt,\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        # 점수 추출 (숫자만 추출)\n",
    "        import re\n",
    "        score_match = re.search(r'(\\d+\\.?\\d*)', score_text.strip())\n",
    "        if score_match:\n",
    "            score = float(score_match.group(1))\n",
    "            # 0-1 범위로 정규화\n",
    "            if score > 1.0:\n",
    "                score = score / 10.0 if score <= 10.0 else 1.0\n",
    "            return max(0.0, min(1.0, score))\n",
    "        else:\n",
    "            return 0.5  # 파싱 실패 시 중간값 반환\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"LLM judge evaluation failed: {e}\")\n",
    "        return 0.5  # 오류 시 중간값 반환\n",
    "\n",
    "def run_dataset_experiment(run_name: str, system_prompt: str):\n",
    "    if not USE_SDK:\n",
    "        print(\"Langfuse SDK unavailable; skipping remote run.\")\n",
    "        return\n",
    "    dataset = langfuse.get_dataset(DATASET_NAME)\n",
    "    total_items = len(dataset.items)\n",
    "    \n",
    "    print(f\"Starting dataset run '{run_name}' with {total_items} items...\")\n",
    "    \n",
    "    for i, item in enumerate(dataset.items, 1):\n",
    "        print(f\"Processing item {i}/{total_items}...\")\n",
    "        \n",
    "        with item.run(run_name=run_name) as root_span:\n",
    "            # 뉴스 요약 생성\n",
    "            output = call_openai_chat(system_prompt, item.input[\"news_article\"])\n",
    "            \n",
    "            # Trace IO를 업데이트해야 Langfuse의 Eval 기능에서 인풋/아웃풋을 인식합니다.\n",
    "            root_span.update_trace(input=item.input, output=output)\n",
    "            \n",
    "            # 1. 구조적 완성도 평가 (기존)\n",
    "            structure_score = presence_of_sections_eval(output, item.expected_output.get(\"sections\", []))\n",
    "            root_span.score_trace(name=\"section_coverage\", value=structure_score)\n",
    "            \n",
    "            # 2. LLM-as-a-judge 품질 평가 (새로 추가)\n",
    "            quality_score = llm_judge_summary_quality(item.input[\"news_article\"], output)\n",
    "            root_span.score_trace(name=\"summary_quality\", value=quality_score)\n",
    "            \n",
    "            # 3. 종합 점수 (구조성 30% + 품질 70%)\n",
    "            overall_score = (structure_score * 0.3) + (quality_score * 0.7)\n",
    "            root_span.score_trace(name=\"overall_score\", value=overall_score)\n",
    "            \n",
    "            print(f\"  - Structure: {structure_score:.3f}, Quality: {quality_score:.3f}, Overall: {overall_score:.3f}\")\n",
    "    \n",
    "    langfuse.flush()\n",
    "    print(f\"Finished dataset run '{run_name}' on dataset '{DATASET_NAME}'.\")\n",
    "\n",
    "# 두 가지 프롬프트 버전에 대한 평가 실행\n",
    "print(\"=\" * 60)\n",
    "print(\"Starting evaluation for both prompt versions...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# V0.0.1 (간단 요약) 평가\n",
    "print(\"\\n🔍 Evaluating V0.0.1 (Simple Summary)...\")\n",
    "run_dataset_experiment(run_name=\"news_summary_v0.0.1\", system_prompt=V001_SIMPLE_SUMMARY)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# V0.0.2 (구조화된 요약) 평가  \n",
    "print(\"\\n🔍 Evaluating V0.0.2 (Structured Summary)...\")\n",
    "run_dataset_experiment(run_name=\"news_summary_v0.0.2\", system_prompt=V002_STRUCTURED_MINUTES)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✅ Evaluation completed! Check Langfuse dashboard for detailed results.\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bdd895",
   "metadata": {},
   "source": [
    "\n",
    "## 8) (선택) Langfuse Prompt 버전 생성 & 라벨 지정 (REST API 예시)\n",
    "\n",
    "- 동일 `promptName`으로 새 버전을 생성하면 자동으로 버전이 증분됩니다.  \n",
    "- `labels`에 `staging`, `production` 등을 부여/변경하여 배포 포인터로 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b72665ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '4b6ae362-fe9c-4734-849e-f76d66765ff8',\n",
       " 'createdAt': '2025-09-21T05:08:59.173Z',\n",
       " 'updatedAt': '2025-09-21T05:08:59.173Z',\n",
       " 'projectId': 'cmfl1scks01diad07dc3azk31',\n",
       " 'createdBy': 'API',\n",
       " 'prompt': \"You are an expert news analyst.\\nSummarize the following news article into a **structured Markdown report** with the following sections:\\n\\n# Headline\\n- A concise title (≤15 words) that captures the main story\\n\\n# Summary\\n- 1–2 paragraphs describing the main events in neutral tone\\n\\n# Key Points\\n- 3–5 bullet points with the most critical facts (who, what, when, where, why, how)\\n\\n# Implications\\n- 2–3 sentences on potential impacts (political, economic, or social)\\n\\n# Quotes\\n- Up to 2 direct quotes if available in the article\\n\\nRules:\\n- Remain objective, no speculation beyond the article content.\\n- Do not exceed 300 words in total.\\n- Preserve named entities (people, organizations, places) accurately.\\n- Write in 'Korean'\\n\",\n",
       " 'name': 'news-summary',\n",
       " 'version': 2,\n",
       " 'type': 'text',\n",
       " 'isActive': None,\n",
       " 'config': {'model_name': 'gpt-4o-mini', 'temperature': 0.2},\n",
       " 'tags': [],\n",
       " 'labels': ['production', 'latest'],\n",
       " 'commitMessage': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import base64, json\n",
    "\n",
    "def lf_auth_headers():\n",
    "    token = base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
    "    return {\"Authorization\": f\"Basic {token}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "def create_prompt_version_via_rest(prompt_name: str, prompt_text: str, model_name: str, labels=None):\n",
    "    if not (LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY):\n",
    "        print(\"Missing Langfuse credentials.\")\n",
    "        return None\n",
    "    import requests\n",
    "    url = f\"{LANGFUSE_HOST.rstrip('/')}/api/public/v2/prompts\"\n",
    "    payload = {\n",
    "        \"name\": prompt_name,\n",
    "        \"prompt\": prompt_text,\n",
    "        \"config\": {\"model_name\": model_name, \"temperature\": 0.2},\n",
    "        \"labels\": labels or []\n",
    "    }\n",
    "    r = requests.post(url, headers=lf_auth_headers(), json=payload, timeout=30)\n",
    "    try:\n",
    "        r.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(\"Prompt creation failed:\", r.status_code, r.text)\n",
    "        raise\n",
    "    return r.json()\n",
    "\n",
    "# 예시: v0.1 → v0.2 (staging → production) 업로드 (주석 해제 후 사용)\n",
    "create_prompt_version_via_rest(\"news-summary\", V001_SIMPLE_SUMMARY, \"gpt-4o-mini\", labels=[\"staging\"])\n",
    "create_prompt_version_via_rest(\"news-summary\", V002_STRUCTURED_MINUTES, \"gpt-4o-mini\", labels=[\"production\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9552155",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Prompty 파일 생성 (GitHub PR용)\n",
    "\n",
    "- `prompts/meeting_minutes_v0.1.prompty`  \n",
    "- `prompts/meeting_minutes_v0.2.prompty`  \n",
    "를 생성합니다. (PR 시 `v0.1 → v0.2` 변경 경험 포함)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669aaa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "print(\"Prompty files:\")\n",
    "for p in Path(\"week03/prompts\").glob(\"*.prompty\"):\n",
    "    print(\"-\", p.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c93ce",
   "metadata": {},
   "source": [
    "\n",
    "## 10) 마무리 & 다음 단계\n",
    "1. **Tracing 확인**: Langfuse 콘솔에서 오늘 생성된 트레이스를 확인합니다.  \n",
    "2. **Dataset Run**: `run_dataset_experiment(...)` 실행 후 지표(예: `section_coverage`) 확인.  \n",
    "3. **Prompt 배포 라벨**: REST 또는 UI로 `staging` → `production` 라벨 전환.  \n",
    "4. **GitHub PR**: `prompts/meeting_minutes_v0.1.prompty` → `v0.2` 변경 포함 PR 생성.  \n",
    "5. **초대**: 프로젝트에 `smilechacha@ajou.ac.kr` 뷰어 이상 권한 초대.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
