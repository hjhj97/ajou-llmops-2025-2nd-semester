{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d5b333b",
   "metadata": {},
   "source": [
    "\n",
    "# Week03 â€” Prompt Evaluation & Version Management (Langfuse + Notion + GitHub)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **ë‰´ìŠ¤ ê¸°ì‚¬ 10ê°œ**ë¥¼ ìž…ë ¥ìœ¼ë¡œ ë°›ì•„,  \n",
    "- **V0.0.1 (ê°„ë‹¨ ìš”ì•½ Prompt)**, **V0.0.2 (êµ¬ì¡°í™”ëœ ë‰´ìŠ¤ ìš”ì•½ Prompt)** ë‘ ë²ˆì˜ Prompt Engineeringì„ ìˆ˜í–‰í•˜ê³ ,  \n",
    "- **Langfuse Tracing**ì„ ë‚¨ê¸°ë©°,  \n",
    "- **Langfuse Datasets**ì— í‰ê°€ìš© ìƒ˜í”Œ 10ê°œë¥¼ ì—…ë¡œë“œí•˜ê³ ,  \n",
    "- ì´í›„ **Dataset Run/Evaluation**ì„ í•  ìˆ˜ ìžˆë„ë¡ ê¸°ë³¸ ì½”ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "> âš™ï¸ ì´ ë…¸íŠ¸ë¶ì€ `.env`ì— ì €ìž¥ëœ ë‹¤ìŒ ë³€ìˆ˜ë“¤ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "> - `LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY`, `LANGFUSE_HOST` (ì˜ˆ: `https://cloud.langfuse.com` ë˜ëŠ” ë¦¬ì „ URL)\n",
    "> - `OPENAI_API_KEY` (ë˜ëŠ” í˜¸í™˜ LLM API í‚¤)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1ccfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langfuse python-dotenv openai requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be11d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env\n",
      "Langfuse host: https://cloud.langfuse.com\n",
      "Langfuse public key set?  True\n",
      "Langfuse secret key set?  True\n",
      "OpenAI key set?  True\n"
     ]
    }
   ],
   "source": [
    "# --- 0) ì„¤ì¹˜ & ê¸°ë³¸ ì„¤ì • ---------------------------------------------------------\n",
    "# ì¸í„°ë„· í™˜ê²½ì— ë”°ë¼ ì„¤ì¹˜ê°€ ì œí•œë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.\n",
    "# %pip install -q langfuse python-dotenv openai requests\n",
    "\n",
    "import os, json, time, uuid, sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "\n",
    "# .env ë¡œë“œ\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    print(\"Loaded .env\")\n",
    "except Exception as e:\n",
    "    print(\"python-dotenv not available; make sure environment variables are set.\")\n",
    "\n",
    "LANGFUSE_PUBLIC_KEY = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
    "LANGFUSE_SECRET_KEY = os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
    "LANGFUSE_HOST = os.getenv(\"LANGFUSE_HOST\", \"https://cloud.langfuse.com\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"Langfuse host:\", LANGFUSE_HOST)\n",
    "print(\"Langfuse public key set? \", bool(LANGFUSE_PUBLIC_KEY))\n",
    "print(\"Langfuse secret key set? \", bool(LANGFUSE_SECRET_KEY))\n",
    "print(\"OpenAI key set? \", bool(OPENAI_API_KEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8ac2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sample news: news_01.txt\n",
      "Length: 1408\n",
      "\n",
      "--- Preview (first 800 chars) ---\n",
      "\n",
      "LGê°€ ëŸ°ë˜ì¦ê¶Œê±°ëž˜ì†Œê·¸ë£¹(LSEG)ì™€ ì†ìž¡ê³  ë…ìž ì¸ê³µì§€ëŠ¥(AI) ëª¨ë¸ â€˜ì—‘ì‚¬ì›â€™(EXAONE)ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ â€˜ê¸ˆìœµ AI ì—ì´ì „íŠ¸â€™ì˜ ìƒìš©í™”ì— ë‚˜ì„°ë‹¤. ì´ë²ˆ í˜‘ì—…ì€ ì–‘êµ­ê°„ ì²« â€˜ê¸ˆìœµ AIâ€™ í˜‘ë ¥ ì‚¬ë¡€ë¡œ, í•œêµ­ì˜ AI ê¸°ìˆ ë ¥ì´ ê¸€ë¡œë²Œ ì‹œìž¥ìœ¼ë¡œ í™•ì‚°í•˜ëŠ” ê³„ê¸°ê°€ ë  ê²ƒìœ¼ë¡œ ì „ë§ëœë‹¤.\n",
      "\n",
      "LGëŠ” ìžì‚¬ AIì—°êµ¬ì›ê³¼ LSEGê°€ ì§€ë‚œ 19ì¼(í˜„ì§€ì‹œê°) ì˜êµ­ ëŸ°ë˜ì¦ê¶Œê±°ëž˜ì†Œì—ì„œ ê¸ˆìœµ AI ì—ì´ì „íŠ¸ â€˜ì—‘ì‚¬ì› ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤â€™ ìƒìš©í™” ì„œë¹„ìŠ¤ ì‹œìž‘ì„ ì•Œë¦¬ëŠ” í–‰ì‚¬ë¥¼ ì§„í–‰í–ˆë‹¤ê³  21ì¼ ë°í˜”ë‹¤.\n",
      "\n",
      "ì´ë‚  í–‰ì‚¬ì—ëŠ” í† ë“œ í•˜íŠ¸ë§Œ ë°ì´í„°Â·í”¼ë“œ ê·¸ë£¹ ì´ê´„, ì´ë³´ ë°ì»¤ìŠ¤ ìœ ëŸ½Â·ì¤‘ë™Â·ì•„í”„ë¦¬ì¹´ ì˜ì—… ê·¸ë£¹ ì´ê´„, ì‚¬ì´ë¨¼ ìœ ë“  í€€íŠ¸Â·ë°ì´í„° ì´ê´„, ì•¤ë“œë¥˜ íŒŒì´í”„ ì•„ì‹œì•„íƒœí‰ì–‘ ì§€ì—­ ì˜ì—… ì´ê´„ì„ ë¹„ë¡¯í•œ LSEG ê²½ì˜ì§„ê³¼ ì´í™ë½ ê³µë™ ì—°êµ¬ì›ìž¥, ìž„ìš°í˜• ê³µë™ ì—°êµ¬ì›ìž¥, ì´í™”ì˜ AIì‚¬ì—…ê°œë°œë¶€ë¬¸ìž¥ ë“± LG AIì—°êµ¬ì› ê²½ì˜ì§„ì´ ì°¸ì„í–ˆë‹¤.\n",
      "\n",
      "í† ë“œ í•˜íŠ¸ë§Œ ì´ê´„ì€ â€œLGì™€ì˜ íŒŒíŠ¸ë„ˆì‹­ì€ ìƒˆë¡œìš´ ì‹œìž‘ì„ ì˜ë¯¸í•œë‹¤â€ë©° â€œAIëŠ” ì „ ì„¸ê³„ íˆ¬ìžìžë“¤ì—ê²Œ ì˜ˆì¸¡ë¶€í„° ì˜ì‚¬ê²°ì • ì§€ì›ì— ì´ë¥´ê¸°ê¹Œì§€ ë” ë‚˜ì€ ê¸°íšŒë¥¼ ì œê³µí•˜ëŠ” í•µì‹¬ì ì¸ ì—­í• ì„ í•  ê²ƒâ€ì´ë¼ê³  ë§í–ˆë‹¤.\n",
      "\n",
      "LSEGëŠ” ê¸€ë¡œë²Œ ê¸ˆìœµ ì¸í”„ë¼Â·ë°ì´í„° ë¶„ì•¼ë¥¼ ì„ ë„í•˜ëŠ” ì˜êµ­ ëŒ€í‘œ ê¸ˆìœµ ê¸°ì—…ìœ¼ë¡œ, ëŸ°ë˜ì¦ê¶Œê±°ëž˜ì†Œë¥¼ ìš´ì˜í•˜ê³  ìžˆë‹¤.\n",
      "\n",
      "LSEGëŠ” ê¸ˆìœµ ì‹œìž¥ì˜ ë°©ëŒ€í•œ ë°ì´í„°ì™€ ì´ë¥¼ ë¶„ì„í•œ ìžë£Œë¥¼ ì „ ì„¸ê³„ íˆ¬ìžìžë“¤ì—ê²Œ ì œê³µí•˜ëŠ” ê²ƒì„ í•µì‹¬ ì‚¬ì—…ìœ¼ë¡œ ì‚¼ê³  ìžˆë‹¤. ì´ í•µì‹¬ ì‚¬ì—…ì— LG AIì—°êµ¬ì›ì˜ ê¸ˆìœµ AI ì—ì´ì „íŠ¸ â€˜ì—‘ì‚¬ì›-BIâ€™ë¥¼ ë„ìž…í•˜ëŠ” ê²ƒì´ë‹¤.\n",
      "\n",
      "â€˜ì—‘ì‚¬ì›-BIâ€™ëŠ” ì¸ê°„ ê°œìž… ì—†ì´ AIê°€ ë°ì´í„° ë¶„ì„ë¶€í„° ë¯¸ëž˜ ì˜ˆì¸¡, ë³´ê³ ì„œ ìž‘ì„±ê¹Œì§€ ì „ ê³¼ì •ì„ ìˆ˜í–‰í•˜ëŠ” â€˜\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1) ë‰´ìŠ¤ ê¸°ì‚¬ ë¡œë“œ ------------------------------------------------------\n",
    "news_dir = Path(\"datasets/news\")\n",
    "news_files = sorted(list(news_dir.glob(\"news_*.txt\")))\n",
    "\n",
    "# ì²« ë²ˆì§¸ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë°ëª¨ìš©ìœ¼ë¡œ ë¡œë“œ\n",
    "sample_news_text = \"\"\n",
    "if news_files:\n",
    "    try:\n",
    "        with open(news_files[0], \"r\", encoding=\"utf-8\") as f:\n",
    "            sample_news_text = f.read()\n",
    "            print(\"Loaded sample news:\", news_files[0].name)\n",
    "            print(\"Length:\", len(sample_news_text))\n",
    "            print(\"\\n--- Preview (first 800 chars) ---\\n\")\n",
    "            print(sample_news_text[:800])\n",
    "    except Exception as e:\n",
    "        print(\"Error loading sample news:\", e)\n",
    "        sample_news_text = \"LGê°€ ëŸ°ë˜ì¦ê¶Œê±°ëž˜ì†Œê·¸ë£¹(LSEG)ì™€ ì†ìž¡ê³  ë…ìž ì¸ê³µì§€ëŠ¥(AI) ëª¨ë¸ 'ì—‘ì‚¬ì›'(EXAONE)ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ 'ê¸ˆìœµ AI ì—ì´ì „íŠ¸'ì˜ ìƒìš©í™”ì— ë‚˜ì„°ë‹¤... (ìƒ˜í”Œ ë‰´ìŠ¤)\"\n",
    "else:\n",
    "    print(\"No news files found in datasets/news directory\")\n",
    "    sample_news_text = \"LGê°€ ëŸ°ë˜ì¦ê¶Œê±°ëž˜ì†Œê·¸ë£¹(LSEG)ì™€ ì†ìž¡ê³  ë…ìž ì¸ê³µì§€ëŠ¥(AI) ëª¨ë¸ 'ì—‘ì‚¬ì›'(EXAONE)ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ 'ê¸ˆìœµ AI ì—ì´ì „íŠ¸'ì˜ ìƒìš©í™”ì— ë‚˜ì„°ë‹¤... (ìƒ˜í”Œ ë‰´ìŠ¤)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108cbc7c",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Prompts â€” V0.0.1 (ê°„ë‹¨ ìš”ì•½) vs V0.0.2 (êµ¬ì¡°í™” íšŒì˜ë¡)\n",
    "\n",
    "- **V0.0.1**: ê°„ë‹¨ ìš”ì•½\n",
    "- **V0.0.2**: ìžì„¸í•œ ìš”ì•½\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "975987be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "V001_SIMPLE_SUMMARY = '''You are a news summarizer.\n",
    "Summarize the following news article in **one short paragraph (max 120 words)**.\n",
    "Focus only on the most important facts: who, what, when, where, and why.\n",
    "Do not add opinions or speculation.\n",
    "\n",
    "Write in 'Korean'\n",
    "'''\n",
    "\n",
    "V002_STRUCTURED_MINUTES = '''You are an expert news analyst.\n",
    "Summarize the following news article into a **structured Markdown report** with the following sections:\n",
    "\n",
    "# Headline\n",
    "- A concise title (â‰¤15 words) that captures the main story\n",
    "\n",
    "# Summary\n",
    "- 1â€“2 paragraphs describing the main events in neutral tone\n",
    "\n",
    "# Key Points\n",
    "- 3â€“5 bullet points with the most critical facts (who, what, when, where, why, how)\n",
    "\n",
    "# Implications\n",
    "- 2â€“3 sentences on potential impacts (political, economic, or social)\n",
    "\n",
    "# Quotes\n",
    "- Up to 2 direct quotes if available in the article\n",
    "\n",
    "Rules:\n",
    "- Remain objective, no speculation beyond the article content.\n",
    "- Do not exceed 300 words in total.\n",
    "- Preserve named entities (people, organizations, places) accurately.\n",
    "- Write in 'Korean'\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73550eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 3) LLM í˜¸ì¶œ ì¶”ìƒí™” -----------------------------------------------------------\n",
    "def call_openai_chat(system_prompt: str, user_text: str, model: str = \"gpt-4o-mini\", temperature: float = 0.2) -> str:\n",
    "    \"\"\"LLM í˜¸ì¶œ. OPENAI_API_KEYê°€ ì—†ìœ¼ë©´ ëª¨ì˜ ì¶œë ¥(mock)ìœ¼ë¡œ ëŒ€ì²´.\"\"\"\n",
    "    if os.getenv(\"OPENAI_API_KEY\"):\n",
    "        try:\n",
    "            # Try official openai package first\n",
    "            try:\n",
    "                from openai import OpenAI\n",
    "                client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_text},\n",
    "                    ],\n",
    "                    temperature=temperature,\n",
    "                )\n",
    "                return resp.choices[0].message.content\n",
    "            except Exception:\n",
    "                # Fallback to raw HTTP if new package not available\n",
    "                import requests\n",
    "                headers = {\n",
    "                    \"Authorization\": f\"Bearer {os.getenv('OPENAI_API_KEY')}\",\n",
    "                    \"Content-Type\": \"application/json\",\n",
    "                }\n",
    "                payload = {\n",
    "                    \"model\": model,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_text},\n",
    "                    ],\n",
    "                    \"temperature\": temperature,\n",
    "                }\n",
    "                r = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload, timeout=60)\n",
    "                r.raise_for_status()\n",
    "                data = r.json()\n",
    "                return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except Exception as e:\n",
    "            print(\"OpenAI call failed, falling back to mock. Error:\", e)\n",
    "    # Mock output for offline demo\n",
    "    return f\"\"\"[MOCK OUTPUT]\\nSystem: {system_prompt.splitlines()[0]}\\nUserInputPreview: {user_text[:120]}...\\n- Bullet 1\\n- Bullet 2\\n- Bullet 3\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec0eb1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse SDK authenticated.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 4) Langfuse ì´ˆê¸°í™” & Tracing ìœ í‹¸ -------------------------------------------\n",
    "USE_SDK = False\n",
    "langfuse = None\n",
    "\n",
    "try:\n",
    "    from langfuse import get_client, observe\n",
    "    from langfuse.openai import OpenAI as LFOpenAI  # optional\n",
    "    langfuse = get_client()\n",
    "    if langfuse and langfuse.auth_check():\n",
    "        USE_SDK = True\n",
    "        print(\"Langfuse SDK authenticated.\")\n",
    "    else:\n",
    "        print(\"Langfuse SDK not authenticated; will use HTTP or no-op.\")\n",
    "except Exception as e:\n",
    "    print(\"Langfuse SDK not available; continuing without it.\", e)\n",
    "\n",
    "def start_trace(name: str, metadata: Dict[str, Any] = None):\n",
    "    if USE_SDK:\n",
    "        # Start span as root trace context manager\n",
    "        return langfuse.start_as_current_span(name=name, metadata=metadata or {})\n",
    "    else:\n",
    "        # No-op context manager\n",
    "        from contextlib import contextmanager\n",
    "        @contextmanager\n",
    "        def _noop():\n",
    "            class Dummy:\n",
    "                def score_trace(self, *args, **kwargs): pass\n",
    "                def update_trace(self, *args, **kwargs): pass\n",
    "            yield Dummy()\n",
    "        return _noop()\n",
    "\n",
    "def log_trace_io(input_obj: Any, output_obj: Any):\n",
    "    if USE_SDK:\n",
    "        try:\n",
    "            # update current trace input/output to enable dataset evals linkage\n",
    "            langfuse.update_current_trace(input=input_obj, output=output_obj)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to update current trace:\", e)\n",
    "\n",
    "def flush_langfuse():\n",
    "    try:\n",
    "        if USE_SDK:\n",
    "            langfuse.flush()\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cc6902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== V0.0.1 (simple) ===\n",
      " LGëŠ” ëŸ°ë˜ì¦ê¶Œê±°ëž˜ì†Œê·¸ë£¹(LSEG)ê³¼ í˜‘ë ¥í•˜ì—¬ ë…ìž ì¸ê³µì§€ëŠ¥ ëª¨ë¸ 'ì—‘ì‚¬ì›'(EXAONE)ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ 'ê¸ˆìœµ AI ì—ì´ì „íŠ¸'ì˜ ìƒìš©í™”ë¥¼ ì‹œìž‘í–ˆë‹¤. ì´ í˜‘ì—…ì€ í•œêµ­ì˜ AI ê¸°ìˆ ì„ ê¸€ë¡œë²Œ ì‹œìž¥ì— í™•ì‚°ì‹œí‚¤ëŠ” ì²« ì‚¬ë¡€ë¡œ, 19ì¼ ëŸ°ë˜ì¦ê¶Œê±°ëž˜ì†Œì—ì„œ ìƒìš©í™” ì„œë¹„ìŠ¤ ì‹œìž‘ì„ ì•Œë¦¬ëŠ” í–‰ì‚¬ê°€ ì—´ë ¸ë‹¤. 'ì—‘ì‚¬ì›-BI'ëŠ” AIê°€ ë°ì´í„° ë¶„ì„, ì˜ˆì¸¡, ë³´ê³ ì„œ ìž‘ì„± ë“±ì„ ìˆ˜í–‰í•˜ë©°, LSEGëŠ” ì´ë¥¼ í†µí•´ ì „ ì„¸ê³„ íˆ¬ìžìžë“¤ì—ê²Œ ë°ì´í„° ìƒí’ˆì„ íŒë§¤í•  ì˜ˆì •ì´ë‹¤. LG AIì—°êµ¬ì›ì€ ì´ AI ì—ì´ì „íŠ¸ê°€ ìƒˆë¡œìš´ AI ì‹œëŒ€ë¥¼ ì—¬ëŠ” ì‹œìž‘ì ì´ ë  ê²ƒìœ¼ë¡œ ê¸°ëŒ€í•˜ê³  ìžˆë‹¤. ...\n",
      "\n",
      "=== V0.0.2 (structured) ===\n",
      " # Headline\n",
      "LG, LSEGì™€ í˜‘ë ¥í•´ ê¸ˆìœµ AI ì—ì´ì „íŠ¸ 'ì—‘ì‚¬ì›' ìƒìš©í™”\n",
      "\n",
      "# Summary\n",
      "LGê°€ ëŸ°ë˜ì¦ê¶Œê±°ëž˜ì†Œê·¸ë£¹(LSEG)ê³¼ í˜‘ë ¥í•˜ì—¬ ë…ìž ì¸ê³µì§€ëŠ¥(AI) ëª¨ë¸ 'ì—‘ì‚¬ì›'(EXAONE)ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ 'ê¸ˆìœµ AI ì—ì´ì „íŠ¸'ì˜ ìƒìš©í™”ì— ë‚˜ì„°ë‹¤. ì´ í˜‘ì—…ì€ í•œêµ­ì˜ AI ê¸°ìˆ ì´ ê¸€ë¡œë²Œ ì‹œìž¥ìœ¼ë¡œ í™•ì‚°í•˜ëŠ” ê³„ê¸°ê°€ ë  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë˜ë©°, ì§€ë‚œ 19ì¼ ì˜êµ­ ëŸ°ë˜ì¦ê¶Œê±°ëž˜ì†Œì—ì„œ ìƒìš©í™” ì„œë¹„ìŠ¤ ì‹œìž‘ì„ ì•Œë¦¬ëŠ” í–‰ì‚¬ê°€ ê°œìµœëë‹¤.\n",
      "\n",
      "í–‰ì‚¬ì—ëŠ” LSEGì™€ LG AIì—°êµ¬ì› ê²½ì˜ì§„ì´ ì°¸ì„í–ˆìœ¼ë©°, LSEGì˜ í† ë“œ í•˜íŠ¸ë§Œ ì´ê´„ì€ LGì™€ì˜ íŒŒíŠ¸ë„ˆì‹­ì´ AIì˜ í•µì‹¬ ì—­í• ì„ ê°•ì¡°í–ˆë‹¤. 'ì—‘ì‚¬ì›-BI'ëŠ” AIê°€ ë°ì´í„° ë¶„ì„ë¶€í„° ì˜ˆì¸¡, ë³´ê³ ì„œ ìž‘ì„±ê¹Œì§€ ì „ ê³¼ì •ì„ ìˆ˜í–‰í•˜ëŠ” ê¸ˆìœµ AI ì—ì´ì „íŠ¸ë¡œ, LSEGëŠ” ì´ë¥¼ í†µí•´ ì „ ì„¸ê³„ íˆ¬ìžìžë“¤ì—ê²Œ ë°ì´í„° ìƒí’ˆì„ íŒë§¤í•  ì˜ˆì •ì´ë‹¤.\n",
      "\n",
      "# Key Points\n",
      "- LGì™€ LSEGê°€ í˜‘ë ¥í•˜ì—¬ 'ì—‘ì‚¬ì›-BI' ê¸ˆìœµ AI ì—ì´ì „íŠ¸ë¥¼ ìƒìš©í™”.\n",
      "- ìƒìš©í™” ë°œí‘œëŠ” 19ì¼ ëŸ°ë˜ì¦ê¶Œê±°ëž˜ì†Œì—ì„œ ì§„í–‰ë¨.\n",
      "- 'ì—‘ì‚¬ì›-BI'ëŠ” AIê°€ ë°ì´í„° ë¶„ì„ê³¼ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ì‹œìŠ¤í…œ.\n",
      "- LSEGëŠ” ì´ AI ì—ì´ì „íŠ¸ë¥¼ í†µí•´ ë°ì´í„° ìƒí’ˆ 'AEFS'ë¥¼ íŒë§¤í•  ê³„íš.\n",
      "- LG AIì—°êµ¬ì›ì€ ì´ í˜‘ë ¥ì´ AIë¥¼ í™œìš©í•œ ìˆ˜ìµ ì°½ì¶œì˜ ì‹œìž‘ì ì´ ë  ê²ƒì´ë¼ê³  ê¸°ëŒ€.\n",
      "\n",
      "# Implications\n",
      "ì´ë²ˆ í˜‘ë ¥ì€ í•œêµ­ì˜ AI ê¸°ìˆ ì´ ê¸€ë¡œë²Œ ê¸ˆìœµ ì‹œìž¥ì—ì„œì˜ ê²½ìŸë ¥ì„ ë†’ì´ëŠ” ê³„ê¸°ê°€ ë  ìˆ˜ ìžˆìœ¼ë©°, AI ê¸°ë°˜ì˜ ë°ì´í„° ë¶„ì„ ì„œë¹„ìŠ¤ê°€ íˆ¬ìžìžë“¤ì—ê²Œ ë” ë‚˜ì€ ì˜ì‚¬ê²°ì • ì§€ì›ì„ ì œê³µí•  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.\n",
      "\n",
      "# Quotes\n",
      "- \"LGì™€ì˜ íŒŒíŠ¸ë„ˆì‹­ì€ ìƒˆë¡œìš´ ì‹œìž‘ì„ ì˜ë¯¸í•œë‹¤.\" - í†  ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 5) ë‘ ê°€ì§€ Prompt ì‹¤í–‰ + Tracing --------------------------------------------\n",
    "subset = sample_news_text[:4000]  # ë°ëª¨ë¥¼ ìœ„í•´ ì•žë¶€ë¶„ë§Œ ì‚¬ìš©\n",
    "\n",
    "results = {}\n",
    "\n",
    "with start_trace(name=\"news-summary:v0.0.1\", metadata={\"version\": \"v0.0.1\", \"label\": \"dev\", \"use_case\":\"news-summary\"}) as span:\n",
    "    out1 = call_openai_chat(V001_SIMPLE_SUMMARY, subset)\n",
    "    results[\"v0.0.1\"] = out1\n",
    "    log_trace_io({\"news_article\": subset, \"prompt_version\": \"v0.0.1\"}, {\"summary\": out1})\n",
    "\n",
    "with start_trace(name=\"news-summary:v0.0.2\", metadata={\"version\": \"v0.0.2\", \"label\": \"staging\", \"use_case\":\"news-summary\"}) as span:\n",
    "    out2 = call_openai_chat(V002_STRUCTURED_MINUTES, subset)\n",
    "    results[\"v0.0.2\"] = out2\n",
    "    log_trace_io({\"news_article\": subset, \"prompt_version\": \"v0.0.2\"}, {\"summary\": out2})\n",
    "\n",
    "flush_langfuse()\n",
    "\n",
    "print(\"\\n=== V0.0.1 (simple) ===\\n\", results[\"v0.0.1\"][:800], \"...\")\n",
    "print(\"\\n=== V0.0.2 (structured) ===\\n\", results[\"v0.0.2\"][:800], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffda36",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Langfuse Dataset ìƒì„± & ì•„ì´í…œ ì—…ë¡œë“œ (ë‰´ìŠ¤ 10ê°œ)\n",
    "\n",
    "- ë‰´ìŠ¤ ê¸°ì‚¬ 10ê°œë¥¼ inputìœ¼ë¡œ, ê¸°ëŒ€ êµ¬ì¡°ë¥¼ referenceë¡œ ì €ìž¥í•©ë‹ˆë‹¤.  \n",
    "- ì´í›„ Langfuseì—ì„œ **Dataset Run**ì„ ì‹¤í–‰í•˜ì—¬, ê° Prompt ë²„ì „ì˜ ê²°ê³¼ë¥¼ ë¹„êµ/í‰ê°€í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "144d0eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 news files\n",
      "Loaded news_01.txt: 1406 characters\n",
      "Loaded news_02.txt: 1231 characters\n",
      "Loaded news_03.txt: 1057 characters\n",
      "Loaded news_04.txt: 764 characters\n",
      "Loaded news_05.txt: 1342 characters\n",
      "Loaded news_06.txt: 1156 characters\n",
      "Loaded news_07.txt: 1476 characters\n",
      "Loaded news_08.txt: 1885 characters\n",
      "Loaded news_09.txt: 989 characters\n",
      "Loaded news_10.txt: 2064 characters\n",
      "\n",
      "Total news items for dataset: 10\n",
      "Created dataset 'week03_news_summary_demo' with 10 items via SDK.\n",
      "Local backup dataset written to /Users/hajuheon/Task/ai/ajou/25-2/llmops/week03/datasets/week03_news_summary_demo.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dataset ì´ë¦„\n",
    "DATASET_NAME = \"week03_news_summary_demo\"\n",
    "\n",
    "# ë‰´ìŠ¤ íŒŒì¼ë“¤ ë¡œë“œ\n",
    "news_dir = Path(\"datasets/news\")\n",
    "news_files = sorted(list(news_dir.glob(\"news_*.txt\")))\n",
    "print(f\"Found {len(news_files)} news files\")\n",
    "\n",
    "# ë‰´ìŠ¤ íŒŒì¼ë“¤ì„ ì½ì–´ì„œ ë°ì´í„°ì…‹ ì•„ì´í…œìœ¼ë¡œ ë³€í™˜\n",
    "news_items = []\n",
    "for news_file in news_files:\n",
    "    try:\n",
    "        with open(news_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read().strip()\n",
    "            if content:  # ë¹ˆ íŒŒì¼ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€\n",
    "                news_items.append({\n",
    "                    \"input\": {\"news_article\": content},\n",
    "                    \"expected_output\": {\n",
    "                        \"sections\": [\"Headline\", \"Summary\", \"Key Points\", \"Implications\", \"Quotes\"],\n",
    "                        \"word_count_limit\": 300\n",
    "                    }\n",
    "                })\n",
    "                print(f\"Loaded {news_file.name}: {len(content)} characters\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {news_file.name}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal news items for dataset: {len(news_items)}\")\n",
    "\n",
    "created = False\n",
    "if USE_SDK:\n",
    "    try:\n",
    "        langfuse.create_dataset(name=DATASET_NAME)\n",
    "        for item in news_items:\n",
    "            langfuse.create_dataset_item(\n",
    "                dataset_name=DATASET_NAME,\n",
    "                input=item[\"input\"],\n",
    "                expected_output=item[\"expected_output\"]\n",
    "            )\n",
    "        created = True\n",
    "        print(f\"Created dataset '{DATASET_NAME}' with {len(news_items)} items via SDK.\")\n",
    "    except Exception as e:\n",
    "        print(\"SDK dataset creation failed:\", e)\n",
    "\n",
    "# ë¡œì»¬ JSONLë„ í•¨ê»˜ ì €ìž¥(ë°±ì—…/ìˆ˜ë™ ì—…ë¡œë“œìš©)\n",
    "ds_dir = Path(\"datasets\"); ds_dir.mkdir(exist_ok=True)\n",
    "jsonl_path = ds_dir / f\"{DATASET_NAME}.jsonl\"\n",
    "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in news_items:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "print(\"Local backup dataset written to\", jsonl_path.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56eb65",
   "metadata": {},
   "source": [
    "\n",
    "## 7) (ì„ íƒ) Native Dataset Run ì‹¤í–‰ ì˜ˆì‹œ\n",
    "\n",
    "ì•„ëž˜ ì½”ë“œëŠ” Langfuse **Datasets Cookbook**ì˜ íŒ¨í„´ì„ ë”°ë¼, ê° Dataset Itemì„ ìˆœíšŒí•˜ë©° ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•˜ê³   \n",
    "`root_span.score_trace(...)` ë“±ìœ¼ë¡œ í‰ê°€ ìŠ¤ì½”ì–´ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.  \n",
    "ì‹¤í–‰ ì „, SDK ì¸ì¦ì´ ë˜ì–´ ìžˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d3d03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_evaluation_results():\n",
    "    \"\"\"\n",
    "    Langfuseì—ì„œ í‰ê°€ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½ í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if not USE_SDK:\n",
    "        print(\"Langfuse SDK unavailable; cannot analyze results.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # ë°ì´í„°ì…‹ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "        dataset = langfuse.get_dataset(DATASET_NAME)\n",
    "        print(f\"\\nðŸ“Š Dataset Analysis: {DATASET_NAME}\")\n",
    "        print(f\"Total items: {len(dataset.items)}\")\n",
    "        \n",
    "        # ê° ì‹¤í–‰ì— ëŒ€í•œ í†µê³„ ê³„ì‚°\n",
    "        runs = [\"news_summary_v0.0.1\", \"news_summary_v0.0.2\"]\n",
    "        \n",
    "        for run_name in runs:\n",
    "            print(f\"\\nðŸ” Run: {run_name}\")\n",
    "            \n",
    "            # í•´ë‹¹ ì‹¤í–‰ì˜ ëª¨ë“  ìŠ¤ì½”ì–´ ìˆ˜ì§‘\n",
    "            scores = {\n",
    "                'section_coverage': [],\n",
    "                'summary_quality': [],\n",
    "                'overall_score': []\n",
    "            }\n",
    "            \n",
    "            for item in dataset.items:\n",
    "                # ê° ì•„ì´í…œì˜ ì‹¤í–‰ ê²°ê³¼ì—ì„œ ìŠ¤ì½”ì–´ ì¶”ì¶œ\n",
    "                # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Langfuse APIë¥¼ í†µí•´ ìŠ¤ì½”ì–´ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì•¼ í•¨\n",
    "                pass\n",
    "            \n",
    "            print(f\"  ðŸ“ˆ Scores will be displayed after evaluation completion\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing results: {e}\")\n",
    "\n",
    "# í‰ê°€ ê²°ê³¼ ë¶„ì„ (ì„ íƒì  ì‹¤í–‰)\n",
    "# analyze_evaluation_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52455b07",
   "metadata": {},
   "source": [
    "## ðŸ“Š LLM-as-a-Judge í‰ê°€ ì‹œìŠ¤í…œ\n",
    "\n",
    "ìœ„ì˜ ì½”ë“œëŠ” ë‰´ìŠ¤ ìš”ì•½ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” **LLM-as-a-Judge** ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í‰ê°€ ì§€í‘œ:\n",
    "\n",
    "1. **`section_coverage`** (êµ¬ì¡°ì  ì™„ì„±ë„, 30% ê°€ì¤‘ì¹˜)\n",
    "   - ìš”ì•½ì´ ì˜ˆìƒ ì„¹ì…˜ë“¤(Headline, Summary, Key Points, Implications, Quotes)ì„ ì–¼ë§ˆë‚˜ ìž˜ í¬í•¨í•˜ëŠ”ì§€ í‰ê°€\n",
    "\n",
    "2. **`summary_quality`** (LLM í’ˆì§ˆ í‰ê°€, 70% ê°€ì¤‘ì¹˜)\n",
    "   - í•µì‹¬ ì •ë³´ ë³´ì¡´ë„ (30%)\n",
    "   - ìš”ì•½ ì •í™•ì„± (25%) \n",
    "   - êµ¬ì¡°ì  ì™„ì„±ë„ (20%)\n",
    "   - ì •ë³´ ì••ì¶•ë„ (15%)\n",
    "   - ê°ê´€ì„± (10%)\n",
    "\n",
    "3. **`overall_score`** (ì¢…í•© ì ìˆ˜)\n",
    "   - êµ¬ì¡°ì  ì™„ì„±ë„ Ã— 0.3 + í’ˆì§ˆ í‰ê°€ Ã— 0.7\n",
    "\n",
    "### ì‚¬ìš©ë²•:\n",
    "1. ìœ„ì˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ë‘ í”„ë¡¬í”„íŠ¸ ë²„ì „ì„ í‰ê°€í•©ë‹ˆë‹¤\n",
    "2. Langfuse ëŒ€ì‹œë³´ë“œì—ì„œ ìƒì„¸í•œ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤\n",
    "3. ê° ë‰´ìŠ¤ ê¸°ì‚¬ë³„ë¡œ ì„¸ ê°€ì§€ ì ìˆ˜ê°€ ê¸°ë¡ë©ë‹ˆë‹¤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f02db63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting evaluation for both prompt versions...\n",
      "============================================================\n",
      "\n",
      "ðŸ” Evaluating V0.0.1 (Simple Summary)...\n",
      "Starting dataset run 'news_summary_v0.0.1' with 10 items...\n",
      "Processing item 1/10...\n",
      "  - Structure: 0.000, Quality: 0.850, Overall: 0.595\n",
      "Processing item 2/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 3/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 4/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 5/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 6/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 7/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 8/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Processing item 9/10...\n",
      "  - Structure: 0.000, Quality: 0.850, Overall: 0.595\n",
      "Processing item 10/10...\n",
      "  - Structure: 0.000, Quality: 0.900, Overall: 0.630\n",
      "Finished dataset run 'news_summary_v0.0.1' on dataset 'week03_news_summary_demo'.\n",
      "\n",
      "============================================================\n",
      "\n",
      "ðŸ” Evaluating V0.0.2 (Structured Summary)...\n",
      "Starting dataset run 'news_summary_v0.0.2' with 10 items...\n",
      "Processing item 1/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 2/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 3/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 4/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 5/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 6/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 7/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 8/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 9/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Processing item 10/10...\n",
      "  - Structure: 1.000, Quality: 0.900, Overall: 0.930\n",
      "Finished dataset run 'news_summary_v0.0.2' on dataset 'week03_news_summary_demo'.\n",
      "\n",
      "============================================================\n",
      "âœ… Evaluation completed! Check Langfuse dashboard for detailed results.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def presence_of_sections_eval(output_text: str, expected_sections) -> float:\n",
    "    \"\"\"ì¶œë ¥ì— ì˜ˆìƒ ì„¹ì…˜ í—¤ë”ê°€ ì–¼ë§ˆë‚˜ í¬í•¨ë˜ëŠ”ì§€ 0.0~1.0 ë°˜í™˜.\"\"\"\n",
    "    if not output_text:\n",
    "        return 0.0\n",
    "    hits = 0\n",
    "    for sec in expected_sections:\n",
    "        if f\"# {sec}\" in output_text or sec in output_text:\n",
    "            hits += 1\n",
    "    return hits / max(1, len(expected_sections))\n",
    "\n",
    "def llm_judge_summary_quality(original_text: str, summary_text: str) -> float:\n",
    "    \"\"\"\n",
    "    LLM-as-a-judge ë°©ì‹ìœ¼ë¡œ ë‰´ìŠ¤ ìš”ì•½ì˜ í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "    0.0~1.0 ìŠ¤ì¼€ì¼ë¡œ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if not original_text or not summary_text:\n",
    "        return 0.0\n",
    "    \n",
    "    evaluation_prompt = f\"\"\"ë‹¹ì‹ ì€ ë‰´ìŠ¤ ìš”ì•½ í’ˆì§ˆ í‰ê°€ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. \n",
    "ë‹¤ìŒ ì›ë¬¸ê³¼ ìš”ì•½ì„ ë¹„êµí•˜ì—¬ ìš”ì•½ì˜ í’ˆì§ˆì„ í‰ê°€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "í‰ê°€ ê¸°ì¤€:\n",
    "1. í•µì‹¬ ì •ë³´ ë³´ì¡´ë„ (30%): ì›ë¬¸ì˜ ì¤‘ìš”í•œ ì‚¬ì‹¤, ì¸ë¬¼, ì‹œê°„, ìž¥ì†Œ, ìˆ«ìž ë“±ì´ ì–¼ë§ˆë‚˜ ìž˜ ë³´ì¡´ë˜ì—ˆëŠ”ê°€?\n",
    "2. ìš”ì•½ ì •í™•ì„± (25%): ìš”ì•½ëœ ë‚´ìš©ì´ ì›ë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ”ê°€? ìž˜ëª»ëœ ì •ë³´ë‚˜ ì™œê³¡ì´ ì—†ëŠ”ê°€?\n",
    "3. êµ¬ì¡°ì  ì™„ì„±ë„ (20%): ìš”ì•½ì´ ë…¼ë¦¬ì ì´ê³  ì½ê¸° ì‰½ê²Œ êµ¬ì„±ë˜ì—ˆëŠ”ê°€?\n",
    "4. ì •ë³´ ì••ì¶•ë„ (15%): ì›ë¬¸ì˜ í•µì‹¬ë§Œì„ íš¨ìœ¨ì ìœ¼ë¡œ ì••ì¶•í–ˆëŠ”ê°€?\n",
    "5. ê°ê´€ì„± (10%): ìš”ì•½ì´ ì¤‘ë¦½ì ì´ê³  ê°ê´€ì ì¸ê°€? ê°œì¸ ì˜ê²¬ì´ë‚˜ ì¶”ì¸¡ì´ ì—†ëŠ”ê°€?\n",
    "\n",
    "ì›ë¬¸:\n",
    "{original_text[:2000]}\n",
    "\n",
    "ìš”ì•½:\n",
    "{summary_text}\n",
    "\n",
    "í‰ê°€ ì ìˆ˜ë¥¼ 0.0ì—ì„œ 1.0 ì‚¬ì´ì˜ ì‹¤ìˆ˜ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. \n",
    "ì¶”ê°€ ì„¤ëª… ì—†ì´ ìˆ«ìžë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "ì˜ˆ: 0.85\"\"\"\n",
    "\n",
    "    try:\n",
    "        score_text = call_openai_chat(\n",
    "            system_prompt=\"ë‹¹ì‹ ì€ ë‰´ìŠ¤ ìš”ì•½ í’ˆì§ˆ í‰ê°€ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. ì£¼ì–´ì§„ ê¸°ì¤€ì— ë”°ë¼ ê°ê´€ì ì´ê³  ì •í™•í•œ í‰ê°€ë¥¼ í•´ì£¼ì„¸ìš”.\",\n",
    "            user_text=evaluation_prompt,\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        # ì ìˆ˜ ì¶”ì¶œ (ìˆ«ìžë§Œ ì¶”ì¶œ)\n",
    "        import re\n",
    "        score_match = re.search(r'(\\d+\\.?\\d*)', score_text.strip())\n",
    "        if score_match:\n",
    "            score = float(score_match.group(1))\n",
    "            # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”\n",
    "            if score > 1.0:\n",
    "                score = score / 10.0 if score <= 10.0 else 1.0\n",
    "            return max(0.0, min(1.0, score))\n",
    "        else:\n",
    "            return 0.5  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¤‘ê°„ê°’ ë°˜í™˜\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"LLM judge evaluation failed: {e}\")\n",
    "        return 0.5  # ì˜¤ë¥˜ ì‹œ ì¤‘ê°„ê°’ ë°˜í™˜\n",
    "\n",
    "def run_dataset_experiment(run_name: str, system_prompt: str):\n",
    "    if not USE_SDK:\n",
    "        print(\"Langfuse SDK unavailable; skipping remote run.\")\n",
    "        return\n",
    "    dataset = langfuse.get_dataset(DATASET_NAME)\n",
    "    total_items = len(dataset.items)\n",
    "    \n",
    "    print(f\"Starting dataset run '{run_name}' with {total_items} items...\")\n",
    "    \n",
    "    for i, item in enumerate(dataset.items, 1):\n",
    "        print(f\"Processing item {i}/{total_items}...\")\n",
    "        \n",
    "        with item.run(run_name=run_name) as root_span:\n",
    "            # ë‰´ìŠ¤ ìš”ì•½ ìƒì„±\n",
    "            output = call_openai_chat(system_prompt, item.input[\"news_article\"])\n",
    "            \n",
    "            # Trace IOë¥¼ ì—…ë°ì´íŠ¸í•´ì•¼ Langfuseì˜ Eval ê¸°ëŠ¥ì—ì„œ ì¸í’‹/ì•„ì›ƒí’‹ì„ ì¸ì‹í•©ë‹ˆë‹¤.\n",
    "            root_span.update_trace(input=item.input, output=output)\n",
    "            \n",
    "            # 1. êµ¬ì¡°ì  ì™„ì„±ë„ í‰ê°€ (ê¸°ì¡´)\n",
    "            structure_score = presence_of_sections_eval(output, item.expected_output.get(\"sections\", []))\n",
    "            root_span.score_trace(name=\"section_coverage\", value=structure_score)\n",
    "            \n",
    "            # 2. LLM-as-a-judge í’ˆì§ˆ í‰ê°€ (ìƒˆë¡œ ì¶”ê°€)\n",
    "            quality_score = llm_judge_summary_quality(item.input[\"news_article\"], output)\n",
    "            root_span.score_trace(name=\"summary_quality\", value=quality_score)\n",
    "            \n",
    "            # 3. ì¢…í•© ì ìˆ˜ (êµ¬ì¡°ì„± 30% + í’ˆì§ˆ 70%)\n",
    "            overall_score = (structure_score * 0.3) + (quality_score * 0.7)\n",
    "            root_span.score_trace(name=\"overall_score\", value=overall_score)\n",
    "            \n",
    "            print(f\"  - Structure: {structure_score:.3f}, Quality: {quality_score:.3f}, Overall: {overall_score:.3f}\")\n",
    "    \n",
    "    langfuse.flush()\n",
    "    print(f\"Finished dataset run '{run_name}' on dataset '{DATASET_NAME}'.\")\n",
    "\n",
    "# ë‘ ê°€ì§€ í”„ë¡¬í”„íŠ¸ ë²„ì „ì— ëŒ€í•œ í‰ê°€ ì‹¤í–‰\n",
    "print(\"=\" * 60)\n",
    "print(\"Starting evaluation for both prompt versions...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# V0.0.1 (ê°„ë‹¨ ìš”ì•½) í‰ê°€\n",
    "print(\"\\nðŸ” Evaluating V0.0.1 (Simple Summary)...\")\n",
    "run_dataset_experiment(run_name=\"news_summary_v0.0.1\", system_prompt=V001_SIMPLE_SUMMARY)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# V0.0.2 (êµ¬ì¡°í™”ëœ ìš”ì•½) í‰ê°€  \n",
    "print(\"\\nðŸ” Evaluating V0.0.2 (Structured Summary)...\")\n",
    "run_dataset_experiment(run_name=\"news_summary_v0.0.2\", system_prompt=V002_STRUCTURED_MINUTES)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… Evaluation completed! Check Langfuse dashboard for detailed results.\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bdd895",
   "metadata": {},
   "source": [
    "\n",
    "## 8) (ì„ íƒ) Langfuse Prompt ë²„ì „ ìƒì„± & ë¼ë²¨ ì§€ì • (REST API ì˜ˆì‹œ)\n",
    "\n",
    "- ë™ì¼ `promptName`ìœ¼ë¡œ ìƒˆ ë²„ì „ì„ ìƒì„±í•˜ë©´ ìžë™ìœ¼ë¡œ ë²„ì „ì´ ì¦ë¶„ë©ë‹ˆë‹¤.  \n",
    "- `labels`ì— `staging`, `production` ë“±ì„ ë¶€ì—¬/ë³€ê²½í•˜ì—¬ ë°°í¬ í¬ì¸í„°ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b72665ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '4b6ae362-fe9c-4734-849e-f76d66765ff8',\n",
       " 'createdAt': '2025-09-21T05:08:59.173Z',\n",
       " 'updatedAt': '2025-09-21T05:08:59.173Z',\n",
       " 'projectId': 'cmfl1scks01diad07dc3azk31',\n",
       " 'createdBy': 'API',\n",
       " 'prompt': \"You are an expert news analyst.\\nSummarize the following news article into a **structured Markdown report** with the following sections:\\n\\n# Headline\\n- A concise title (â‰¤15 words) that captures the main story\\n\\n# Summary\\n- 1â€“2 paragraphs describing the main events in neutral tone\\n\\n# Key Points\\n- 3â€“5 bullet points with the most critical facts (who, what, when, where, why, how)\\n\\n# Implications\\n- 2â€“3 sentences on potential impacts (political, economic, or social)\\n\\n# Quotes\\n- Up to 2 direct quotes if available in the article\\n\\nRules:\\n- Remain objective, no speculation beyond the article content.\\n- Do not exceed 300 words in total.\\n- Preserve named entities (people, organizations, places) accurately.\\n- Write in 'Korean'\\n\",\n",
       " 'name': 'news-summary',\n",
       " 'version': 2,\n",
       " 'type': 'text',\n",
       " 'isActive': None,\n",
       " 'config': {'model_name': 'gpt-4o-mini', 'temperature': 0.2},\n",
       " 'tags': [],\n",
       " 'labels': ['production', 'latest'],\n",
       " 'commitMessage': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import base64, json\n",
    "\n",
    "def lf_auth_headers():\n",
    "    token = base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
    "    return {\"Authorization\": f\"Basic {token}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "def create_prompt_version_via_rest(prompt_name: str, prompt_text: str, model_name: str, labels=None):\n",
    "    if not (LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY):\n",
    "        print(\"Missing Langfuse credentials.\")\n",
    "        return None\n",
    "    import requests\n",
    "    url = f\"{LANGFUSE_HOST.rstrip('/')}/api/public/v2/prompts\"\n",
    "    payload = {\n",
    "        \"name\": prompt_name,\n",
    "        \"prompt\": prompt_text,\n",
    "        \"config\": {\"model_name\": model_name, \"temperature\": 0.2},\n",
    "        \"labels\": labels or []\n",
    "    }\n",
    "    r = requests.post(url, headers=lf_auth_headers(), json=payload, timeout=30)\n",
    "    try:\n",
    "        r.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(\"Prompt creation failed:\", r.status_code, r.text)\n",
    "        raise\n",
    "    return r.json()\n",
    "\n",
    "# ì˜ˆì‹œ: v0.1 â†’ v0.2 (staging â†’ production) ì—…ë¡œë“œ (ì£¼ì„ í•´ì œ í›„ ì‚¬ìš©)\n",
    "create_prompt_version_via_rest(\"news-summary\", V001_SIMPLE_SUMMARY, \"gpt-4o-mini\", labels=[\"staging\"])\n",
    "create_prompt_version_via_rest(\"news-summary\", V002_STRUCTURED_MINUTES, \"gpt-4o-mini\", labels=[\"production\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9552155",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Prompty íŒŒì¼ ìƒì„± (GitHub PRìš©)\n",
    "\n",
    "- `prompts/meeting_minutes_v0.1.prompty`  \n",
    "- `prompts/meeting_minutes_v0.2.prompty`  \n",
    "ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (PR ì‹œ `v0.1 â†’ v0.2` ë³€ê²½ ê²½í—˜ í¬í•¨)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669aaa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "print(\"Prompty files:\")\n",
    "for p in Path(\"week03/prompts\").glob(\"*.prompty\"):\n",
    "    print(\"-\", p.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c93ce",
   "metadata": {},
   "source": [
    "\n",
    "## 10) ë§ˆë¬´ë¦¬ & ë‹¤ìŒ ë‹¨ê³„\n",
    "1. **Tracing í™•ì¸**: Langfuse ì½˜ì†”ì—ì„œ ì˜¤ëŠ˜ ìƒì„±ëœ íŠ¸ë ˆì´ìŠ¤ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.  \n",
    "2. **Dataset Run**: `run_dataset_experiment(...)` ì‹¤í–‰ í›„ ì§€í‘œ(ì˜ˆ: `section_coverage`) í™•ì¸.  \n",
    "3. **Prompt ë°°í¬ ë¼ë²¨**: REST ë˜ëŠ” UIë¡œ `staging` â†’ `production` ë¼ë²¨ ì „í™˜.  \n",
    "4. **GitHub PR**: `prompts/meeting_minutes_v0.1.prompty` â†’ `v0.2` ë³€ê²½ í¬í•¨ PR ìƒì„±.  \n",
    "5. **ì´ˆëŒ€**: í”„ë¡œì íŠ¸ì— `smilechacha@ajou.ac.kr` ë·°ì–´ ì´ìƒ ê¶Œí•œ ì´ˆëŒ€.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
